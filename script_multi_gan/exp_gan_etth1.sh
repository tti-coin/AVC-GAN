# ETTh1
# Synthesizing
# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 192 \
# --pred_len 192 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 5000 \
# --sample_size 8448

# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 192 \
# --pred_len 192 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 10000 \
# --sample_size 8448

# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 192 \
# --pred_len 192 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 15000 \
# --sample_size 8448

# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 288 \
# --pred_len 288 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 20000 \
# --sample_size 8352

# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 432 \
# --pred_len 432 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 20000 \
# --sample_size 8208

# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 0 \
# --is_synthesizig 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 816 \
# --pred_len 816 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --no_wandb \
# --load_iter 20000 \
# --sample_size 7824


# Training
# python run_gan.py \
# --is_gan_training 1 \
# --is_gan_evaluating 0 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 192 \
# --pred_len 192 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id gan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 40000 \
# --no_wandb 
# --wandb_notes "Experiments to generate 192 steps with non-conditional WGAN"


# Evaluation
python run_gan.py \
--is_gan_training 0 \
--is_gan_evaluating 1 \
--root_path ./data/iTransformer_datasets/ETT-small/ \
--data_path ETTh1.csv \
--model_id ae \
--model iTransformer \
--d_model 128 \
--data ETTh1 \
--features M \
--seq_len 192 \
--pred_len 192 \
--e_layers 2 \
--enc_in 7 \
--dec_in 7 \
--c_out 7 \
--des etth1 \
--ae_batch_size 32 \
--train_epochs 100 \
--patience 10 \
--learning_rate 0.001 \
--gan_model_id gan \
--use_hidden \
--gan_batch_size 1024 \
--gen_lr 0.0001 \
--disc_lr 0.0001 \
--noise_dim 128 \
--d_update 10 \
--gan_iter 20000 \
--sample_size 4096 \
--load_iter 20000 \
--no_wandb


python run_gan.py \
--is_gan_training 1 \
--is_gan_evaluating 0 \
--root_path ./data/iTransformer_datasets/ETT-small/ \
--data_path ETTh1.csv \
--model_id ae \
--model iTransformer \
--d_model 128 \
--data ETTh1 \
--features M \
--seq_len 288 \
--pred_len 288 \
--e_layers 2 \
--enc_in 7 \
--dec_in 7 \
--c_out 7 \
--des etth1 \
--ae_batch_size 32 \
--train_epochs 100 \
--patience 10 \
--learning_rate 0.001 \
--gan_model_id gan \
--use_hidden \
--gan_batch_size 1024 \
--gen_lr 0.0001 \
--disc_lr 0.0001 \
--noise_dim 128 \
--d_update 10 \
--gan_iter 20000 \
--no_wandb
# --wandb_notes "Experiments to generate 288 steps with non-conditional WGAN"


# Evaluation
python run_gan.py \
--is_gan_training 0 \
--is_gan_evaluating 1 \
--root_path ./data/iTransformer_datasets/ETT-small/ \
--data_path ETTh1.csv \
--model_id ae \
--model iTransformer \
--d_model 128 \
--data ETTh1 \
--features M \
--seq_len 288 \
--pred_len 288 \
--e_layers 2 \
--enc_in 7 \
--dec_in 7 \
--c_out 7 \
--des etth1 \
--ae_batch_size 32 \
--train_epochs 100 \
--patience 10 \
--learning_rate 0.001 \
--gan_model_id gan \
--use_hidden \
--gan_batch_size 1024 \
--gen_lr 0.0001 \
--disc_lr 0.0001 \
--noise_dim 128 \
--d_update 10 \
--gan_iter 20000 \
--sample_size 4096 \
--load_iter 20000 \
--no_wandb


# python run_gan.py \
# --is_gan_training 1 \
# --is_gan_evaluating 0 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 432 \
# --pred_len 432 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --wandb_notes "Experiments to generate 432 steps with non-conditional AutoEncoder"


# # Evaluation
# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 432 \
# --pred_len 432 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --sample_size 4096 \
# --load_iter 20000 \
# --wandb_notes "Experiments to generate 432 steps with non-conditional AutoEncoder" \
# --no_wandb


# python run_gan.py \
# --is_gan_training 1 \
# --is_gan_evaluating 0 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 816 \
# --pred_len 816 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --wandb_notes "Experiments to generate 816 steps with non-conditional AutoEncoder"


# # Evaluation
# python run_gan.py \
# --is_gan_training 0 \
# --is_gan_evaluating 1 \
# --root_path ./data/iTransformer_datasets/ETT-small/ \
# --data_path ETTh1.csv \
# --model_id ae \
# --model iTransformer \
# --d_model 128 \
# --data ETTh1 \
# --features M \
# --seq_len 816 \
# --pred_len 816 \
# --e_layers 2 \
# --enc_in 7 \
# --dec_in 7 \
# --c_out 7 \
# --des etth1 \
# --ae_batch_size 32 \
# --train_epochs 100 \
# --patience 10 \
# --learning_rate 0.001 \
# --gan_model_id cgan \
# --use_hidden \
# --gan_batch_size 1024 \
# --gen_lr 0.0001 \
# --disc_lr 0.0001 \
# --noise_dim 128 \
# --d_update 10 \
# --gan_iter 20000 \
# --sample_size 4096 \
# --load_iter 20000 \
# --wandb_notes "Experiments to generate 816 steps with non-conditional AutoEncoder" \
# --no_wandb